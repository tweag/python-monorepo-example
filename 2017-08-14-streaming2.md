---
title: Composable streaming programs
author: Facundo DomÃ­nguez
featured: yes
---

In our first [streaming post](http://www.tweag.io/posts/2017-07-27-streaming-programs.html)
we showed how streaming libraries strengthen types to catch more
errors. Strengthening types, though, sometimes can make it harder
to have the compiler accept a program since it demands more
evidence that the program is correct. In this post, we show that
this is not the case for programs written with streaming libraries,
as they still can be conveniently composed.


# Composition forms

In large strokes, streaming libraries offer two flavors of composition:
appending and pipelining. When appending, the values produced by one
program are followed by the values produced by another.
When pipelining, some values produced by one streaming program are
processed by another while the first program still has more values to
produce. 

Different libraries implement these forms of composition in different
ways. Let us consider first the streaming libraries which
manipulate stream processors. In simple terms, a stream processors
`SP i o m r` gets a stream of values of type
`i`, yields a stream of values of type `o`, and it yields a value of
type `r` when it terminates. The parameter `m` stands for the monad
in which the effects of the processors are sequenced.

```Haskell
conduit:    ConduitM i o m r
pipes:      Pipe i o m r
```

[pipes](http://hackage.haskell.org/package/pipes)
and
[conduit](http://hackage.haskell.org/package/conduit)
define the monad bind operation (`>>=`) as an appending
composition. In `p >>= \r -> q`, the input stream is first given to
`p` until it completes, and then the remainder is given to `q`.
Similarly, the output stream of `p` is followed by the output stream
of `q`.

The packages
[streaming](http://hackage.haskell.org/package/streaming)
and
[io-stream](http://hackage.haskell.org/package/io-streams)
manipulate streams instead.
Unlike stream processors, streams have no *input stream*. Still, monadic
composition works similarly in the case of the package `streaming`. The
stream `p >>= \r -> q` starts with the *output stream* of values produced
by `p`, followed by the *output stream* of values produced by `q`.

```Haskell
streaming: Stream (Of a) m r
io-streams: InputStream a
```

The package `io-stream` does not define a monad instance for
`InputStream` but it provides

```Haskell
appendInputStream :: InputStream a -> InputStream a -> IO (InputStream a)
```

Stream processors have an additional form of pipeline composition.

```Haskell
conduit:    (.|) :: Monad m => ConduitM a b m () -> ConduitM b c m r -> ConduitM a c m r
pipes:      (>->) :: Monad m => Pipe a b m r -> Pipe b c m r -> Pipe a c m r
``` 

In `p .| q`, the output stream of `p` is fed as the input stream of
`q`. In the packages `streaming` and `io-streams`, pipelines are made
by composing functions which transform streams. For instance

```Haskell
streaming:  map :: (a -> b) -> (Stream (Of a) m r) -> Stream (Of b) m r
io-streams: decompress :: InputStream ByteString -> IO (InputStream ByteString)
```

## Leftovers and parsing

Most streaming libraries offer the ability to push back a value from
the input. The returned input is sometimes called leftovers. It is
useful to observe some look-ahead elements to drive the behavior of
the program.

The following 'conduit' program acts as a parser which yields the amount
of `'a'` characters found in the input followed by the amount of `'b'`
characters.

```Haskell
abConduit :: Monad m => Consumer Char m (Int, Int)
abConduit =
    (,) <$> (takeWhileC (== 'a') .| lengthC)
        <*> (takeWhileC (== 'b') .| lengthC)
```

As `conduit` implements leftovers, the first `takeWhileC` can return an
element to the input stream upon discovering that it isn't an `'a'`
character. Then the following `takeWhile` has the opportunity to
examine it.

The pipelining composition only allows the left operand to put values
back. That is, in `p .| q`, only `p` is allowed to return values to
the input stream and `q` leftovers are ignored. This is a constraint
streaming from the type of the composition:

```Haskell
(.|) :: Monad m => ConduitM a b m () -> ConduitM b c m r -> ConduitM a c m r
```

The input stream provides values of type `a`, but the leftovers of the
right operand are of type `b`. To address this, `conduit` offers the
following composition operator that resolves the type mismatch with
a conversion function.

```Haskell
fuseLeftovers :: Monad m => ([b] -> [a]) -> ConduitM a b m () -> ConduitM b c m r -> ConduitM a c m r
```

The package `pipes` does not implement leftovers but there is the
package [pipes-parse](http://hackage.haskell.org/package/pipes-parse)
which defines `Parser`s in terms of the core
abstraction of `Pipe`s. `Parser`s in turn use lenses of the input to
return values back. This is what an implementation with `pipes-parse`
looks like for our running example.

```Haskell
abPipes :: Monad m => Pipes.Parse.Parser Text m (Int, Int)
abPipes =
   (,) <$> zoom (Pipes.Text.span (== 'a')) lengthP
       <*> zoom (Pipes.Text.span (== 'b')) lengthP

lengthP :: (Monad m, Num n) => Pipes.Parse.Parser Text m n
lengthP =
    Pipes.Parse.foldAll (\n txt -> n + fromIntegral (Text.length txt)) 0 id
```
The function `zoom` is a primitive offered by packages implementing
lenses. It changes the state of a stateful computation in a given scope,
and a lens explains how the state is changed.
```Haskell
zoom :: Monad m => Lens' a b -> StateT b m c -> StateT a m c
```
In the case of `zoom (Pipes.Text.span (== 'a')) p` it changes the input
fed to the parser `p` by only giving the greatest prefix containing
`'a'`s. The rest of the input, even the first character failing the
predicate, is left for the next parser.

The parser `lengthP` is defined to count the amount of characters in the
input. Thus
```Haskell
zoom (Pipes.Text.span (== 'a')) lengthP :: Parser Text m Int
```
stands for the same computation as
```Haskell
takeWhileC (== 'a') .| lengthC :: Consumer Char m Int
```

`Stream`s from the package `streaming` provide `cons` to push back
values into a stream. The package `io-streams` provides `unRead`.
While the function `cons` would just construct a new stream, the
function `unRead` modifies the input stream. 

```Haskell
cons :: Monad m => a -> Stream (Of a) m r -> Stream (Of a) m r
unRead :: a -> InputStream a -> IO ()
```

Should streaming libraries try to do the job of parsers? Surely, it
is convenient to have some parsing capabilities. After all, parsing
libraries like
[parsec](http://hackage.haskell.org/package/parsec) or
[attoparsec](http://hackage.haskell.org/package/attoparsec)
do not promise to
achieve bounded memory consumption. The parsers of neither library
return values before the whole input has been parsed. For instance,
if a parser is parsing a list, it can't yield the first elements of the
list as they are discovered. The list is handled to the caller only
when all of it resides in memory. The package `attoparsec` is even more
problematic as it claims to retain all of the input, no matter what the
parser does.

More sophisticated parsing libraries can do better, e.g.
[uu-parsinglib](http://foswiki.cs.uu.nl/foswiki/HUT/ParserCombinators).
This package , however, returns the parser results lazily
and it poses the challenge of testing whether specific parts of the
result are available without blocking the program.


# Folds and non-linear uses of streams

The following program is an incorrect attempt to compute the average
of a stream of values.

```Haskell
average0 :: Stream (Of Double) IO () -> IO Double
average0 xs = (/) <$> Streaming.Prelude.sum_ xs
                  <*> (fromIntegral <$> Streaming.Prelude.length_ xs)
```

The problem with this program is that the same stream is traversed
twice. If the stream is not effectful, this program does not run in
bounded memory. If the stream is effectful, then each traversal
produces different results. It can be fixed by computing the length
and the average in a single pass.

```Haskell
average1 :: Stream (Of Double) IO () -> IO Double
average1 xs = uncurry (/) <$>
    Streaming.Prelude.fold_ (\(!s, !c) d -> (s + 1, c + 1)) (0, 0) id xs
```

With `conduit`s and `pipes` one can screw and fix the program in a
similar way. Thus, streaming libraries seem to require that the programmer
consumes streaming sources in linear fashion, that is, at most once in
a program.

Interestingly, `conduit` offers an alternative solution, where existing
stream processors can be reused and combined using `ZipSink`s instead of
writing a `fold`. A `ZipSink` is a combination of stream
processors, all of which are fed the same input stream, and a final
result is produced from the outputs of all the output streams.

```Haskell
average2 :: Monad m => Consumer Double m Double
average2 = toConsumer $
    getZipSink ((/) <$> ZipSink sumC <*> fmap fromIntegral (ZipSink lengthC))
```


# Summary

While strengthening types to catch more errors, streaming libraries are still
expressive enough to write many data flow patterns of streaming programs.
The basic composition forms are complemented with other solutions to reach
further patterns. Leftovers, for instance, were brought to accomplish parsing
tasks which can't be easily delegated to parsing libraries while keeping
memory bounded; and `ZipSink`s were introduced to share an input stream
with multiple stream processors.
