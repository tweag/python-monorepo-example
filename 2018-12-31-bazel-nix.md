---
title: Nix + Bazel = <br/> fully reproducible, incremental builds
shortTitle: Nix + Bazel = fully reproducible, incremental builds
author: Mathieu Boespflug, Th√©ophane Hufschmitt
---

A `Makefile` is an extraordinary thing. You specify a set of targets,
you tell Make what the dependencies are between these targets, and
Make figures out how to create these in the right order, every time.

```makefile
foo.o: foo.c foo.h
        gcc -c foo.c

bar.o: bar.c
        gcc -c bar.c

hello: foo.o bar.o
       gcc -o foo.o bar.o
```

The number one problem with this kind of build system today?
Reproducibility. After an initial `git clone` of a new project, it's
all too common to have to install a long list of "build requirements"
and plod through multiple steps of "setup", only to find that yes
indeed, the build did fail. Yet it worked just fine for your
colleague! Now you have to find out why. One reason might be that the
compiler toolchain on your system is different from that of your
colleague. Technically, `gcc` itself is a dependency of each of the
above targets, but developers don't say so in their `Makefile`.
Instead of building GCC from scratch, they *implicitly* reuse whatever
is part of your system's state.

In fact this also frequently happens with system upgrades. `apt-get
install` does not do a full reinstallation from scratch of your system
every time you call it. If it did, chances would be high that
`apt-get` would systematically succeed, because nothing-at-all is
a known good starting state for your system, so following
a deterministic sequence of steps starting from that state will get
your system, as well as everyone else's system, to the same final
state every time. That's why some folks today use [Nix][nix] instead.
Nix is a package manager just like `apt-get`. But unlike `apt-get` and
other package managers, Nix is the only tool that will reinstall your
system from scratch, every time. Sounds crazy? Reinstalling from
scratch is actually much faster than you might think, for reasons
we'll discuss below. The point is that build tools and package
management tools both have sometimes poor reproducibility, in both
cases because they don't start from scratch *completely* each and
every time. Nix solves the problem for package management, but what
about for builds? If a remedy works for Bob, could the same one work
for Alice? That's what we'll explore in this post.

But let's not bury the lede too far down. We'll argue that you want
to use Nix to "build" your entire compiler toolchain and system
libraries, but use [Bazel][bazel] to build your code base to achieve
fast, correct and incremental rebuilds.

## Hermeticity

Truly starting a build from scratch effectively means making it so
that the build is entirely self-contained. It means that building your
project requires *nothing* in `/usr/bin`, `/usr/lib`, `/usr/include`
or anywhere else in your system, apart from the build command. In
a self-contained build, we can't just grab the compiler from the
`PATH`. The only possible way forward is to make the compiler
toolchain itself one of the targets in the build, and then make all
targets that need a compiler depend on it. We can't just include
whatever headers we find in the filesystem. We need to supply our own.
We can't link against system libraries. We need to build those
libraries, then link against that.

That sounds like a lot of work. So why do that? Because in this way,
we can precisely control the version of the compiler toolchain, ensure
header files are byte-for-byte identical to what we expect, and use
system libraries that we know for sure won't cause linking issues.

It also sounds like a long time. If you have to build yourself an
entire compiler before you can even get started in earnest, you might
need a *lot* of coffee breaks. But the good news is that hermetic
build targets are easy to cache in globally available storage. Because
by definition, hermeticity means targets don't depend on anything
outside the build, it means that anything produced as part of the
build is a closed artifact that can be copied across different systems
easily. Build artifacts aren't affected by different environments on
different systems, because they don't use it.

The [Nixpkgs project][nixpkgs] defines a lot of compiler toolchains,
header files and system libraries once and for all. You can reuse
these definitions as snippets of your projet's build description. If
you do so, then you're sharing the same snippets as others are. So you
"building" them can be very quick indeed: just check whether the
target is already in the cache because someone else already built it,
and if so download it.

We could bring our own build definitions for these standard things
like glibc, GCC, OpenJDK, zlib etc. The benefit of reusing the
definitions from Nixpkgs is,

* we don't have to painstakingly put together these build definitions,
* we get the benefit of the public Nixpkgs build caches.

## Incremental rebuilds

## Example Nix+Bazel project

## Conclusion
